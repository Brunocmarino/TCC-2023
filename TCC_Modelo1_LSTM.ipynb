{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlqmFZBUetAAvSYf+cqpog"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install tensorflow"
      ],
      "metadata": {
        "id": "tv8hksk9EiSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8nnpjk8Vo2p"
      },
      "outputs": [],
      "source": [
        "# Importar as bibliotecas necessárias\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# Importar sklearn para avaliar o modelo\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
        "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
        "from sklearn.preprocessing  import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "# Importar tensorflow para construir o modelo\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint, History\n",
        "from keras.losses import MeanSquaredError\n",
        "from keras.metrics import RootMeanSquaredError\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Importar bibliotecas para plotar gráficos\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import cycle\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Variaveis Globais"
      ],
      "metadata": {
        "id": "N_nI01hq-LBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TIME_STEP = 15\n",
        "JUMP_STEP = 1\n",
        "NUM_FEATURES = 5\n",
        "THRESHOLD = 1\n",
        "# usando apenas o Close\n"
      ],
      "metadata": {
        "id": "2zbng1cT-UhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importar a Base de Dados"
      ],
      "metadata": {
        "id": "syo9xluyeRry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = 'BTC-USD'\n",
        "#1410825600\n",
        "initial_period = int(time.mktime(datetime.datetime(2014, 9, 16, 0, 0).timetuple()))\n",
        "\n",
        "#1675814400\n",
        "final_period = int(time.mktime(datetime.datetime(2023, 2, 8, 0, 0).timetuple()))\n",
        "# 3067 valores. 2300 é 75%\n",
        "interval = '1d' # 1d, 1wk, 1m\n",
        "\n",
        "query_string = f'https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={initial_period}&period2={final_period}&interval={interval}&events=history&includeAdjustedClose=true'\n",
        "\n",
        "data = pd.read_csv(query_string)\n",
        "df = pd.DataFrame(data, columns=['Date', 'Open', 'High', 'Low', 'Close', 'Volume'])\n",
        "df.index = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Dmlyft24aP-0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "e06acff3-baf4-4ee3-cc58-17baf2da5c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Date        Open        High         Low       Close  \\\n",
              "Date                                                                     \n",
              "2014-09-17  2014-09-17  465.864014  468.174011  452.421997  457.334015   \n",
              "2014-09-18  2014-09-18  456.859985  456.859985  413.104004  424.440002   \n",
              "2014-09-19  2014-09-19  424.102997  427.834991  384.532013  394.795990   \n",
              "2014-09-20  2014-09-20  394.673004  423.295990  389.882996  408.903992   \n",
              "2014-09-21  2014-09-21  408.084991  412.425995  393.181000  398.821014   \n",
              "\n",
              "              Volume  \n",
              "Date                  \n",
              "2014-09-17  21056800  \n",
              "2014-09-18  34483200  \n",
              "2014-09-19  37919700  \n",
              "2014-09-20  36863600  \n",
              "2014-09-21  26580100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-959c2ec0-8aa9-4462-9bee-a57d37801bb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-09-17</th>\n",
              "      <td>2014-09-17</td>\n",
              "      <td>465.864014</td>\n",
              "      <td>468.174011</td>\n",
              "      <td>452.421997</td>\n",
              "      <td>457.334015</td>\n",
              "      <td>21056800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-18</th>\n",
              "      <td>2014-09-18</td>\n",
              "      <td>456.859985</td>\n",
              "      <td>456.859985</td>\n",
              "      <td>413.104004</td>\n",
              "      <td>424.440002</td>\n",
              "      <td>34483200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-19</th>\n",
              "      <td>2014-09-19</td>\n",
              "      <td>424.102997</td>\n",
              "      <td>427.834991</td>\n",
              "      <td>384.532013</td>\n",
              "      <td>394.795990</td>\n",
              "      <td>37919700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-20</th>\n",
              "      <td>2014-09-20</td>\n",
              "      <td>394.673004</td>\n",
              "      <td>423.295990</td>\n",
              "      <td>389.882996</td>\n",
              "      <td>408.903992</td>\n",
              "      <td>36863600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-21</th>\n",
              "      <td>2014-09-21</td>\n",
              "      <td>408.084991</td>\n",
              "      <td>412.425995</td>\n",
              "      <td>393.181000</td>\n",
              "      <td>398.821014</td>\n",
              "      <td>26580100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-959c2ec0-8aa9-4462-9bee-a57d37801bb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-959c2ec0-8aa9-4462-9bee-a57d37801bb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-959c2ec0-8aa9-4462-9bee-a57d37801bb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função para escolher os dados utilizados de forma sequencial. A cada t valores\n"
      ],
      "metadata": {
        "id": "XL9rvrxc--7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def selecionaValores(df, jump_step):\n",
        "  return df[0::jump_step]\n",
        "\n",
        "df = selecionaValores(df, JUMP_STEP)"
      ],
      "metadata": {
        "id": "Q_vBUR_C_PA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparação dos Dados:"
      ],
      "metadata": {
        "id": "7ntbbIvr59kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retira a Data e coloca como Index\n",
        "df.index = df.pop('Date')\n",
        "\n",
        "# Adição da coluna de variação\n",
        "df['TargetChange'] = df.Close.shift(-1) - df['Close']\n",
        "# Adição da coluna de variação percentual\n",
        "df['TargetVariation'] = (df['TargetChange'] / df['Close'])*100\n",
        "# Adição da coluna de classificação\n",
        "df['TargetClass'] = [0 if df.TargetVariation[i] >= THRESHOLD else 1 if df.TargetVariation[i] <= (-THRESHOLD) else 2 for i in range(len(df))]\n",
        "# Adição da coluna de Valor Final\n",
        "df['TargetClose'] = df['Close'].shift(-1)\n",
        "\n",
        "# df.pop('TargetVariation')\n",
        "# df.pop('TargetClass')\n",
        "# df.pop('TargetClose')\n",
        "data.dropna(inplace=True)\n",
        "data.reset_index(inplace = True)\n"
      ],
      "metadata": {
        "id": "1eGnvTzf6Czd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "MFJDEReCl6zL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "d24a5b7c-e644-432d-ad31-599df7a54ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Open        High         Low       Close    Volume  \\\n",
              "Date                                                                   \n",
              "2014-09-17  465.864014  468.174011  452.421997  457.334015  21056800   \n",
              "2014-09-18  456.859985  456.859985  413.104004  424.440002  34483200   \n",
              "2014-09-19  424.102997  427.834991  384.532013  394.795990  37919700   \n",
              "2014-09-20  394.673004  423.295990  389.882996  408.903992  36863600   \n",
              "2014-09-21  408.084991  412.425995  393.181000  398.821014  26580100   \n",
              "\n",
              "            TargetChange  TargetVariation  TargetClass  TargetClose  \n",
              "Date                                                                 \n",
              "2014-09-17    -32.894013        -7.192558            1   424.440002  \n",
              "2014-09-18    -29.644012        -6.984264            1   394.795990  \n",
              "2014-09-19     14.108002         3.573492            0   408.903992  \n",
              "2014-09-20    -10.082978        -2.465855            1   398.821014  \n",
              "2014-09-21      3.330994         0.835210            2   402.152008  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-150a34b4-3be2-4988-8f8a-0ec5632c2aa6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>TargetChange</th>\n",
              "      <th>TargetVariation</th>\n",
              "      <th>TargetClass</th>\n",
              "      <th>TargetClose</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2014-09-17</th>\n",
              "      <td>465.864014</td>\n",
              "      <td>468.174011</td>\n",
              "      <td>452.421997</td>\n",
              "      <td>457.334015</td>\n",
              "      <td>21056800</td>\n",
              "      <td>-32.894013</td>\n",
              "      <td>-7.192558</td>\n",
              "      <td>1</td>\n",
              "      <td>424.440002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-18</th>\n",
              "      <td>456.859985</td>\n",
              "      <td>456.859985</td>\n",
              "      <td>413.104004</td>\n",
              "      <td>424.440002</td>\n",
              "      <td>34483200</td>\n",
              "      <td>-29.644012</td>\n",
              "      <td>-6.984264</td>\n",
              "      <td>1</td>\n",
              "      <td>394.795990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-19</th>\n",
              "      <td>424.102997</td>\n",
              "      <td>427.834991</td>\n",
              "      <td>384.532013</td>\n",
              "      <td>394.795990</td>\n",
              "      <td>37919700</td>\n",
              "      <td>14.108002</td>\n",
              "      <td>3.573492</td>\n",
              "      <td>0</td>\n",
              "      <td>408.903992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-20</th>\n",
              "      <td>394.673004</td>\n",
              "      <td>423.295990</td>\n",
              "      <td>389.882996</td>\n",
              "      <td>408.903992</td>\n",
              "      <td>36863600</td>\n",
              "      <td>-10.082978</td>\n",
              "      <td>-2.465855</td>\n",
              "      <td>1</td>\n",
              "      <td>398.821014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-09-21</th>\n",
              "      <td>408.084991</td>\n",
              "      <td>412.425995</td>\n",
              "      <td>393.181000</td>\n",
              "      <td>398.821014</td>\n",
              "      <td>26580100</td>\n",
              "      <td>3.330994</td>\n",
              "      <td>0.835210</td>\n",
              "      <td>2</td>\n",
              "      <td>402.152008</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-150a34b4-3be2-4988-8f8a-0ec5632c2aa6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-150a34b4-3be2-4988-8f8a-0ec5632c2aa6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-150a34b4-3be2-4988-8f8a-0ec5632c2aa6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(df.index, df['Close'])"
      ],
      "metadata": {
        "id": "kYaFYGojLbfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa as Features do Valor Final\n",
        "# Separa X de Y e Retira a última linha\n",
        "y_array = np.array(df.TargetClass)[:-1].copy()\n",
        "#df.pop('Open')\n",
        "#df.pop('High')\n",
        "#df.pop('Low')\n",
        "#df.pop('Volume')\n",
        "df.pop('TargetChange')\n",
        "df.pop('TargetVariation')\n",
        "df.pop('TargetClass')\n",
        "df.pop('TargetClose')\n",
        "x_array = np.array(df)[:-1].copy()\n"
      ],
      "metadata": {
        "id": "iSj1CwbZsIpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforma os dados para suavizar as variações em escala absoluta\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "x_scaled_data = scaler.fit_transform(x_array)\n",
        "#Talvez usar apenas transform em teste e não fit_transform"
      ],
      "metadata": {
        "id": "0cj30FewVA38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# n = timestep = 3 no exemplo abaixo\n",
        "# [[[1], [2], [3]]] => [4]\n",
        "# [[[2], [3], [4]]] => [5]\n",
        "# [[[3], [4], [5]]] => [6]\n",
        "\n",
        "def createDataset(x, y, time_step=1):\n",
        "  input = []\n",
        "  output = []\n",
        "  for i in range(len(x) - time_step):\n",
        "    row = [e for e in x[i : i + time_step]]\n",
        "    input.append(row)\n",
        "    output.append([y[i]])\n",
        "  return np.array(input), np.array(output)\n",
        "\n",
        "x_data, y_data = createDataset(x_scaled_data, y_array, TIME_STEP)\n",
        "print(df.shape)\n",
        "print(x_data.shape, y_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkOFLEGQ6E6Z",
        "outputId": "935c613a-6853-4860-ff74-c90bb4aae7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3067, 5)\n",
            "(3051, 15, 5) (3051, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data\")\n",
        "data_count = [0, 0, 0]\n",
        "for i in range(y_data.shape[0]):\n",
        "  if(y_data[i]==1):\n",
        "    data_count[1]+=1\n",
        "  elif(y_data[i]==2):\n",
        "    data_count[2]+=1\n",
        "  else:\n",
        "    data_count[0]+=1\n",
        "print(data_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFv1MHI2bP9a",
        "outputId": "468163a7-a33a-4e5c-ce26-140e1b03cfe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data\n",
            "[1049, 871, 1131]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparar os dados para Treino e Teste\n",
        "\n"
      ],
      "metadata": {
        "id": "SHj7ga8Hji3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divisão entre 70% treino, 10% validação e 20% teste\n",
        "size = len(df-1) - TIME_STEP\n",
        "train_size = int(size * 0.7)\n",
        "validation_size = int(size * 0.1)\n",
        "test_size = size - train_size - validation_size\n",
        "\n",
        "x_train, y_train = x_data[: train_size], y_data[: train_size]\n",
        "x_val, y_val = x_data[train_size : (train_size + validation_size)], y_data[train_size : (train_size + validation_size)]\n",
        "x_test, y_test = x_data[(train_size + validation_size) :], y_data[(train_size + validation_size) :]\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_val.shape, y_val.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "#[samples, time steps, features]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN1vXbqXzgjh",
        "outputId": "b5351991-7369-44a9-8c9b-df7d307093f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2136, 15, 5) (2136, 1)\n",
            "(305, 15, 5) (305, 1)\n",
            "(610, 15, 5) (610, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imprime informações sobre os dados"
      ],
      "metadata": {
        "id": "Mpqd1OjXhLXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantos valores temos de cada classe\n",
        "# Lateralizou, Subiu, Caiu\n",
        "\n",
        "print(\"Train\")\n",
        "train_count = [0, 0, 0]\n",
        "for i in range(train_size):\n",
        "  if(y_train[i]==1):\n",
        "    train_count[1]+=1\n",
        "  elif(y_train[i]==2):\n",
        "    train_count[2]+=1\n",
        "  else:\n",
        "    train_count[0]+=1\n",
        "print(train_count)\n",
        "\n",
        "print(\"Test\")\n",
        "test_count = [0, 0, 0]\n",
        "for i in range(test_size-1):\n",
        "  if(y_test[i]==1):\n",
        "    test_count[1]+=1\n",
        "  elif(y_test[i]==2):\n",
        "    test_count[2]+=1\n",
        "  else:\n",
        "    test_count[0]+=1\n",
        "print(test_count)\n",
        "\n",
        "print(\"Validation\")\n",
        "val_count = [0, 0, 0]\n",
        "for i in range(validation_size):\n",
        "  if(y_val[i]==1):\n",
        "    val_count[1]+=1\n",
        "  elif(y_val[i]==2):\n",
        "    val_count[2]+=1\n",
        "  else:\n",
        "    val_count[0]+=1\n",
        "print(val_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrc1CowJV56M",
        "outputId": "71e4667f-9906-47bb-b630-b04c1b4d3aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "[723, 583, 830]\n",
            "Test\n",
            "[197, 199, 214]\n",
            "Validation\n",
            "[129, 89, 87]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construção do Modelo LSTM"
      ],
      "metadata": {
        "id": "5FjYMbeLgA7H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo: LSTM\n",
        "\n"
      ],
      "metadata": {
        "id": "DJ54UplFDQZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To One-Hot\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes=3)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes=3)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=3)\n"
      ],
      "metadata": {
        "id": "OoP6ZV_K9wFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vklTZX2ISaN",
        "outputId": "26af12b6-6aaf-4e9f-f3da-b463217054b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2136, 15, 5) (2136, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create the sequence model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=64, activation=\"softmax\", return_sequences=True, input_shape=(x_train.shape[1], x_train.shape[2])))\n",
        "    model.add(LSTM(units=32, activation=\"softmax\", return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(units=3,activation=\"softmax\"))\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "76_OIh_iSBVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classificação\n",
        "\n",
        "model = create_model()\n",
        "#https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=200, batch_size=32)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HP32S8oOc-5O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875869b0-478f-43d4-b0a5-1f7d5d1a3064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 15, 64)            17920     \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 32)                12416     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,435\n",
            "Trainable params: 30,435\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "67/67 [==============================] - 6s 33ms/step - loss: 1.0965 - accuracy: 0.3652 - val_loss: 1.1001 - val_accuracy: 0.2852\n",
            "Epoch 2/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0921 - accuracy: 0.3890 - val_loss: 1.1010 - val_accuracy: 0.2852\n",
            "Epoch 3/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0905 - accuracy: 0.3886 - val_loss: 1.1029 - val_accuracy: 0.2852\n",
            "Epoch 4/200\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 1.0893 - accuracy: 0.3886 - val_loss: 1.1031 - val_accuracy: 0.2852\n",
            "Epoch 5/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0889 - accuracy: 0.3886 - val_loss: 1.1047 - val_accuracy: 0.2852\n",
            "Epoch 6/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1055 - val_accuracy: 0.2852\n",
            "Epoch 7/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1062 - val_accuracy: 0.2852\n",
            "Epoch 8/200\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1066 - val_accuracy: 0.2852\n",
            "Epoch 9/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0884 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 10/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1067 - val_accuracy: 0.2852\n",
            "Epoch 11/200\n",
            "67/67 [==============================] - 2s 30ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1060 - val_accuracy: 0.2852\n",
            "Epoch 12/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1063 - val_accuracy: 0.2852\n",
            "Epoch 13/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1062 - val_accuracy: 0.2852\n",
            "Epoch 14/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 15/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0881 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 16/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0884 - accuracy: 0.3886 - val_loss: 1.1065 - val_accuracy: 0.2852\n",
            "Epoch 17/200\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 1.0889 - accuracy: 0.3886 - val_loss: 1.1063 - val_accuracy: 0.2852\n",
            "Epoch 18/200\n",
            "67/67 [==============================] - 2s 31ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1070 - val_accuracy: 0.2852\n",
            "Epoch 19/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1068 - val_accuracy: 0.2852\n",
            "Epoch 20/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1070 - val_accuracy: 0.2852\n",
            "Epoch 21/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1059 - val_accuracy: 0.2852\n",
            "Epoch 22/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1068 - val_accuracy: 0.2852\n",
            "Epoch 23/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 24/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1070 - val_accuracy: 0.2852\n",
            "Epoch 25/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1071 - val_accuracy: 0.2852\n",
            "Epoch 26/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1063 - val_accuracy: 0.2852\n",
            "Epoch 27/200\n",
            "67/67 [==============================] - 2s 31ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1060 - val_accuracy: 0.2852\n",
            "Epoch 28/200\n",
            "67/67 [==============================] - 3s 48ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1065 - val_accuracy: 0.2852\n",
            "Epoch 29/200\n",
            "67/67 [==============================] - 3s 43ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1063 - val_accuracy: 0.2852\n",
            "Epoch 30/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1066 - val_accuracy: 0.2852\n",
            "Epoch 31/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1067 - val_accuracy: 0.2852\n",
            "Epoch 32/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0884 - accuracy: 0.3886 - val_loss: 1.1069 - val_accuracy: 0.2852\n",
            "Epoch 33/200\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1072 - val_accuracy: 0.2852\n",
            "Epoch 34/200\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1063 - val_accuracy: 0.2852\n",
            "Epoch 35/200\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1066 - val_accuracy: 0.2852\n",
            "Epoch 36/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1065 - val_accuracy: 0.2852\n",
            "Epoch 37/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0880 - accuracy: 0.3886 - val_loss: 1.1069 - val_accuracy: 0.2852\n",
            "Epoch 38/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1062 - val_accuracy: 0.2852\n",
            "Epoch 39/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1070 - val_accuracy: 0.2852\n",
            "Epoch 40/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1068 - val_accuracy: 0.2852\n",
            "Epoch 41/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1062 - val_accuracy: 0.2852\n",
            "Epoch 42/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 43/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1061 - val_accuracy: 0.2852\n",
            "Epoch 44/200\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1059 - val_accuracy: 0.2852\n",
            "Epoch 45/200\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1066 - val_accuracy: 0.2852\n",
            "Epoch 46/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0890 - accuracy: 0.3886 - val_loss: 1.1067 - val_accuracy: 0.2852\n",
            "Epoch 47/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1062 - val_accuracy: 0.2852\n",
            "Epoch 48/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1065 - val_accuracy: 0.2852\n",
            "Epoch 49/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1067 - val_accuracy: 0.2852\n",
            "Epoch 50/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0884 - accuracy: 0.3886 - val_loss: 1.1066 - val_accuracy: 0.2852\n",
            "Epoch 51/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1063 - val_accuracy: 0.2852\n",
            "Epoch 52/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1066 - val_accuracy: 0.2852\n",
            "Epoch 53/200\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1058 - val_accuracy: 0.2852\n",
            "Epoch 54/200\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1060 - val_accuracy: 0.2852\n",
            "Epoch 55/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0884 - accuracy: 0.3886 - val_loss: 1.1065 - val_accuracy: 0.2852\n",
            "Epoch 56/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1061 - val_accuracy: 0.2852\n",
            "Epoch 57/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1057 - val_accuracy: 0.2852\n",
            "Epoch 58/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1060 - val_accuracy: 0.2852\n",
            "Epoch 59/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1063 - val_accuracy: 0.2852\n",
            "Epoch 60/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1060 - val_accuracy: 0.2852\n",
            "Epoch 61/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1065 - val_accuracy: 0.2852\n",
            "Epoch 62/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 63/200\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1057 - val_accuracy: 0.2852\n",
            "Epoch 64/200\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1066 - val_accuracy: 0.2852\n",
            "Epoch 65/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0879 - accuracy: 0.3886 - val_loss: 1.1060 - val_accuracy: 0.2852\n",
            "Epoch 66/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1056 - val_accuracy: 0.2852\n",
            "Epoch 67/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0881 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 68/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1055 - val_accuracy: 0.2852\n",
            "Epoch 69/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1067 - val_accuracy: 0.2852\n",
            "Epoch 70/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1064 - val_accuracy: 0.2852\n",
            "Epoch 71/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0881 - accuracy: 0.3886 - val_loss: 1.1057 - val_accuracy: 0.2852\n",
            "Epoch 72/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0882 - accuracy: 0.3886 - val_loss: 1.1059 - val_accuracy: 0.2852\n",
            "Epoch 73/200\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 1.0881 - accuracy: 0.3886 - val_loss: 1.1059 - val_accuracy: 0.2852\n",
            "Epoch 74/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0877 - accuracy: 0.3886 - val_loss: 1.1053 - val_accuracy: 0.2852\n",
            "Epoch 75/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0885 - accuracy: 0.3886 - val_loss: 1.1057 - val_accuracy: 0.2852\n",
            "Epoch 76/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0880 - accuracy: 0.3886 - val_loss: 1.1050 - val_accuracy: 0.2852\n",
            "Epoch 77/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1061 - val_accuracy: 0.2852\n",
            "Epoch 78/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0884 - accuracy: 0.3886 - val_loss: 1.1049 - val_accuracy: 0.2852\n",
            "Epoch 79/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0888 - accuracy: 0.3886 - val_loss: 1.1059 - val_accuracy: 0.2852\n",
            "Epoch 80/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0884 - accuracy: 0.3886 - val_loss: 1.1053 - val_accuracy: 0.2852\n",
            "Epoch 81/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1056 - val_accuracy: 0.2852\n",
            "Epoch 82/200\n",
            "67/67 [==============================] - 2s 30ms/step - loss: 1.0881 - accuracy: 0.3886 - val_loss: 1.1047 - val_accuracy: 0.2852\n",
            "Epoch 83/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0881 - accuracy: 0.3886 - val_loss: 1.1055 - val_accuracy: 0.2852\n",
            "Epoch 84/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0881 - accuracy: 0.3886 - val_loss: 1.1061 - val_accuracy: 0.2852\n",
            "Epoch 85/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0886 - accuracy: 0.3886 - val_loss: 1.1051 - val_accuracy: 0.2852\n",
            "Epoch 86/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0879 - accuracy: 0.3886 - val_loss: 1.1049 - val_accuracy: 0.2852\n",
            "Epoch 87/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1049 - val_accuracy: 0.2852\n",
            "Epoch 88/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0887 - accuracy: 0.3886 - val_loss: 1.1046 - val_accuracy: 0.2852\n",
            "Epoch 89/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0880 - accuracy: 0.3886 - val_loss: 1.1045 - val_accuracy: 0.2852\n",
            "Epoch 90/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0876 - accuracy: 0.3886 - val_loss: 1.1041 - val_accuracy: 0.2852\n",
            "Epoch 91/200\n",
            "67/67 [==============================] - 3s 38ms/step - loss: 1.0878 - accuracy: 0.3886 - val_loss: 1.1047 - val_accuracy: 0.2852\n",
            "Epoch 92/200\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 1.0879 - accuracy: 0.3886 - val_loss: 1.1046 - val_accuracy: 0.2852\n",
            "Epoch 93/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0878 - accuracy: 0.3886 - val_loss: 1.1043 - val_accuracy: 0.2852\n",
            "Epoch 94/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0877 - accuracy: 0.3886 - val_loss: 1.1034 - val_accuracy: 0.2852\n",
            "Epoch 95/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0883 - accuracy: 0.3886 - val_loss: 1.1039 - val_accuracy: 0.2852\n",
            "Epoch 96/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0876 - accuracy: 0.3886 - val_loss: 1.1037 - val_accuracy: 0.2852\n",
            "Epoch 97/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0876 - accuracy: 0.3886 - val_loss: 1.1041 - val_accuracy: 0.2852\n",
            "Epoch 98/200\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 1.0869 - accuracy: 0.3886 - val_loss: 1.1024 - val_accuracy: 0.2852\n",
            "Epoch 99/200\n",
            "67/67 [==============================] - 2s 25ms/step - loss: 1.0874 - accuracy: 0.3886 - val_loss: 1.1023 - val_accuracy: 0.2852\n",
            "Epoch 100/200\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 1.0868 - accuracy: 0.3886 - val_loss: 1.1018 - val_accuracy: 0.2852\n",
            "Epoch 101/200\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 1.0863 - accuracy: 0.3886 - val_loss: 1.1002 - val_accuracy: 0.2852\n",
            "Epoch 102/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0858 - accuracy: 0.3886 - val_loss: 1.0987 - val_accuracy: 0.2852\n",
            "Epoch 103/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0855 - accuracy: 0.3895 - val_loss: 1.0974 - val_accuracy: 0.2852\n",
            "Epoch 104/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0863 - accuracy: 0.3886 - val_loss: 1.0969 - val_accuracy: 0.2852\n",
            "Epoch 105/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0844 - accuracy: 0.3895 - val_loss: 1.0962 - val_accuracy: 0.2852\n",
            "Epoch 106/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0851 - accuracy: 0.3886 - val_loss: 1.0949 - val_accuracy: 0.2852\n",
            "Epoch 107/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0864 - accuracy: 0.3844 - val_loss: 1.0941 - val_accuracy: 0.4000\n",
            "Epoch 108/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0872 - accuracy: 0.3834 - val_loss: 1.0940 - val_accuracy: 0.4033\n",
            "Epoch 109/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0863 - accuracy: 0.3825 - val_loss: 1.0935 - val_accuracy: 0.4131\n",
            "Epoch 110/200\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 1.0861 - accuracy: 0.3890 - val_loss: 1.0938 - val_accuracy: 0.4033\n",
            "Epoch 111/200\n",
            "67/67 [==============================] - 1s 22ms/step - loss: 1.0836 - accuracy: 0.3900 - val_loss: 1.0939 - val_accuracy: 0.4033\n",
            "Epoch 112/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0852 - accuracy: 0.3867 - val_loss: 1.0925 - val_accuracy: 0.4230\n",
            "Epoch 113/200\n",
            "67/67 [==============================] - 1s 17ms/step - loss: 1.0854 - accuracy: 0.3834 - val_loss: 1.0924 - val_accuracy: 0.4230\n",
            "Epoch 114/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0855 - accuracy: 0.3942 - val_loss: 1.0920 - val_accuracy: 0.4230\n",
            "Epoch 115/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0835 - accuracy: 0.4082 - val_loss: 1.0921 - val_accuracy: 0.4230\n",
            "Epoch 116/200\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 1.0859 - accuracy: 0.3806 - val_loss: 1.0915 - val_accuracy: 0.4230\n",
            "Epoch 117/200\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 1.0849 - accuracy: 0.3919 - val_loss: 1.0922 - val_accuracy: 0.4230\n",
            "Epoch 118/200\n",
            "67/67 [==============================] - 2s 23ms/step - loss: 1.0838 - accuracy: 0.3951 - val_loss: 1.0914 - val_accuracy: 0.4230\n",
            "Epoch 119/200\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 1.0857 - accuracy: 0.3848 - val_loss: 1.0912 - val_accuracy: 0.4230\n",
            "Epoch 120/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0833 - accuracy: 0.4017 - val_loss: 1.0912 - val_accuracy: 0.4230\n",
            "Epoch 121/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0857 - accuracy: 0.3965 - val_loss: 1.0909 - val_accuracy: 0.4230\n",
            "Epoch 122/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0838 - accuracy: 0.3942 - val_loss: 1.0907 - val_accuracy: 0.4230\n",
            "Epoch 123/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0826 - accuracy: 0.4059 - val_loss: 1.0901 - val_accuracy: 0.4230\n",
            "Epoch 124/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0843 - accuracy: 0.3998 - val_loss: 1.0901 - val_accuracy: 0.4230\n",
            "Epoch 125/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0870 - accuracy: 0.3844 - val_loss: 1.0898 - val_accuracy: 0.4230\n",
            "Epoch 126/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0830 - accuracy: 0.4007 - val_loss: 1.0905 - val_accuracy: 0.4230\n",
            "Epoch 127/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0827 - accuracy: 0.4031 - val_loss: 1.0900 - val_accuracy: 0.4230\n",
            "Epoch 128/200\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 1.0826 - accuracy: 0.4022 - val_loss: 1.0895 - val_accuracy: 0.4230\n",
            "Epoch 129/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0842 - accuracy: 0.3867 - val_loss: 1.0896 - val_accuracy: 0.4230\n",
            "Epoch 130/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0852 - accuracy: 0.3998 - val_loss: 1.0897 - val_accuracy: 0.4230\n",
            "Epoch 131/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0819 - accuracy: 0.4148 - val_loss: 1.0893 - val_accuracy: 0.4230\n",
            "Epoch 132/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0840 - accuracy: 0.3904 - val_loss: 1.0895 - val_accuracy: 0.4230\n",
            "Epoch 133/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0837 - accuracy: 0.3998 - val_loss: 1.0891 - val_accuracy: 0.4230\n",
            "Epoch 134/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0835 - accuracy: 0.4031 - val_loss: 1.0890 - val_accuracy: 0.4230\n",
            "Epoch 135/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0856 - accuracy: 0.3947 - val_loss: 1.0895 - val_accuracy: 0.4230\n",
            "Epoch 136/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0841 - accuracy: 0.3904 - val_loss: 1.0885 - val_accuracy: 0.4230\n",
            "Epoch 137/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0825 - accuracy: 0.3970 - val_loss: 1.0893 - val_accuracy: 0.4230\n",
            "Epoch 138/200\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 1.0807 - accuracy: 0.4017 - val_loss: 1.0888 - val_accuracy: 0.4230\n",
            "Epoch 139/200\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 1.0844 - accuracy: 0.3989 - val_loss: 1.0887 - val_accuracy: 0.4230\n",
            "Epoch 140/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0837 - accuracy: 0.4022 - val_loss: 1.0887 - val_accuracy: 0.4230\n",
            "Epoch 141/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0810 - accuracy: 0.4134 - val_loss: 1.0887 - val_accuracy: 0.4230\n",
            "Epoch 142/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0837 - accuracy: 0.3890 - val_loss: 1.0881 - val_accuracy: 0.4230\n",
            "Epoch 143/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0845 - accuracy: 0.3975 - val_loss: 1.0881 - val_accuracy: 0.4230\n",
            "Epoch 144/200\n",
            "67/67 [==============================] - 1s 21ms/step - loss: 1.0851 - accuracy: 0.3844 - val_loss: 1.0883 - val_accuracy: 0.4230\n",
            "Epoch 145/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0842 - accuracy: 0.3956 - val_loss: 1.0887 - val_accuracy: 0.4230\n",
            "Epoch 146/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0847 - accuracy: 0.4059 - val_loss: 1.0893 - val_accuracy: 0.4230\n",
            "Epoch 147/200\n",
            "67/67 [==============================] - 2s 30ms/step - loss: 1.0843 - accuracy: 0.4003 - val_loss: 1.0889 - val_accuracy: 0.4230\n",
            "Epoch 148/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0813 - accuracy: 0.4036 - val_loss: 1.0884 - val_accuracy: 0.4230\n",
            "Epoch 149/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0814 - accuracy: 0.4171 - val_loss: 1.0883 - val_accuracy: 0.4230\n",
            "Epoch 150/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0836 - accuracy: 0.3993 - val_loss: 1.0880 - val_accuracy: 0.4230\n",
            "Epoch 151/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0842 - accuracy: 0.4073 - val_loss: 1.0881 - val_accuracy: 0.4230\n",
            "Epoch 152/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0842 - accuracy: 0.3979 - val_loss: 1.0885 - val_accuracy: 0.4230\n",
            "Epoch 153/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0842 - accuracy: 0.4050 - val_loss: 1.0882 - val_accuracy: 0.4230\n",
            "Epoch 154/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0835 - accuracy: 0.3965 - val_loss: 1.0878 - val_accuracy: 0.4230\n",
            "Epoch 155/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0838 - accuracy: 0.3989 - val_loss: 1.0881 - val_accuracy: 0.4230\n",
            "Epoch 156/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0809 - accuracy: 0.4050 - val_loss: 1.0880 - val_accuracy: 0.4230\n",
            "Epoch 157/200\n",
            "67/67 [==============================] - 2s 29ms/step - loss: 1.0828 - accuracy: 0.4040 - val_loss: 1.0881 - val_accuracy: 0.4230\n",
            "Epoch 158/200\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 1.0825 - accuracy: 0.4167 - val_loss: 1.0879 - val_accuracy: 0.4230\n",
            "Epoch 159/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0842 - accuracy: 0.4017 - val_loss: 1.0881 - val_accuracy: 0.4230\n",
            "Epoch 160/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0818 - accuracy: 0.4036 - val_loss: 1.0876 - val_accuracy: 0.4230\n",
            "Epoch 161/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0828 - accuracy: 0.4087 - val_loss: 1.0875 - val_accuracy: 0.4230\n",
            "Epoch 162/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0846 - accuracy: 0.3989 - val_loss: 1.0879 - val_accuracy: 0.4230\n",
            "Epoch 163/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0839 - accuracy: 0.4078 - val_loss: 1.0876 - val_accuracy: 0.4230\n",
            "Epoch 164/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0824 - accuracy: 0.4031 - val_loss: 1.0878 - val_accuracy: 0.4230\n",
            "Epoch 165/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0834 - accuracy: 0.3993 - val_loss: 1.0875 - val_accuracy: 0.4230\n",
            "Epoch 166/200\n",
            "67/67 [==============================] - 2s 27ms/step - loss: 1.0837 - accuracy: 0.4054 - val_loss: 1.0880 - val_accuracy: 0.4230\n",
            "Epoch 167/200\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 1.0832 - accuracy: 0.3965 - val_loss: 1.0877 - val_accuracy: 0.4230\n",
            "Epoch 168/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0826 - accuracy: 0.3993 - val_loss: 1.0874 - val_accuracy: 0.4230\n",
            "Epoch 169/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0851 - accuracy: 0.4078 - val_loss: 1.0875 - val_accuracy: 0.4230\n",
            "Epoch 170/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0844 - accuracy: 0.4064 - val_loss: 1.0873 - val_accuracy: 0.4230\n",
            "Epoch 171/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0821 - accuracy: 0.4054 - val_loss: 1.0872 - val_accuracy: 0.4230\n",
            "Epoch 172/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0839 - accuracy: 0.4003 - val_loss: 1.0876 - val_accuracy: 0.4230\n",
            "Epoch 173/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0838 - accuracy: 0.4064 - val_loss: 1.0871 - val_accuracy: 0.4230\n",
            "Epoch 174/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0832 - accuracy: 0.4017 - val_loss: 1.0874 - val_accuracy: 0.4230\n",
            "Epoch 175/200\n",
            "67/67 [==============================] - 2s 24ms/step - loss: 1.0812 - accuracy: 0.4115 - val_loss: 1.0871 - val_accuracy: 0.4230\n",
            "Epoch 176/200\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 1.0824 - accuracy: 0.3975 - val_loss: 1.0876 - val_accuracy: 0.4230\n",
            "Epoch 177/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0823 - accuracy: 0.4101 - val_loss: 1.0869 - val_accuracy: 0.4230\n",
            "Epoch 178/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0824 - accuracy: 0.4096 - val_loss: 1.0867 - val_accuracy: 0.4230\n",
            "Epoch 179/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0830 - accuracy: 0.4040 - val_loss: 1.0865 - val_accuracy: 0.4230\n",
            "Epoch 180/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0821 - accuracy: 0.4036 - val_loss: 1.0871 - val_accuracy: 0.4230\n",
            "Epoch 181/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0835 - accuracy: 0.4031 - val_loss: 1.0868 - val_accuracy: 0.4230\n",
            "Epoch 182/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0836 - accuracy: 0.4054 - val_loss: 1.0867 - val_accuracy: 0.4230\n",
            "Epoch 183/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0809 - accuracy: 0.3993 - val_loss: 1.0865 - val_accuracy: 0.4230\n",
            "Epoch 184/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0814 - accuracy: 0.4082 - val_loss: 1.0863 - val_accuracy: 0.4230\n",
            "Epoch 185/200\n",
            "67/67 [==============================] - 2s 28ms/step - loss: 1.0815 - accuracy: 0.4059 - val_loss: 1.0861 - val_accuracy: 0.4230\n",
            "Epoch 186/200\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 1.0809 - accuracy: 0.4026 - val_loss: 1.0863 - val_accuracy: 0.4230\n",
            "Epoch 187/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0809 - accuracy: 0.3947 - val_loss: 1.0856 - val_accuracy: 0.4230\n",
            "Epoch 188/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0826 - accuracy: 0.4012 - val_loss: 1.0855 - val_accuracy: 0.4230\n",
            "Epoch 189/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0823 - accuracy: 0.4078 - val_loss: 1.0855 - val_accuracy: 0.4230\n",
            "Epoch 190/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0821 - accuracy: 0.4022 - val_loss: 1.0856 - val_accuracy: 0.4230\n",
            "Epoch 191/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0832 - accuracy: 0.4110 - val_loss: 1.0859 - val_accuracy: 0.4230\n",
            "Epoch 192/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0819 - accuracy: 0.4007 - val_loss: 1.0858 - val_accuracy: 0.4230\n",
            "Epoch 193/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0825 - accuracy: 0.4040 - val_loss: 1.0856 - val_accuracy: 0.4230\n",
            "Epoch 194/200\n",
            "67/67 [==============================] - 2s 26ms/step - loss: 1.0822 - accuracy: 0.4007 - val_loss: 1.0854 - val_accuracy: 0.4230\n",
            "Epoch 195/200\n",
            "67/67 [==============================] - 2s 30ms/step - loss: 1.0833 - accuracy: 0.3993 - val_loss: 1.0857 - val_accuracy: 0.4230\n",
            "Epoch 196/200\n",
            "67/67 [==============================] - 1s 19ms/step - loss: 1.0821 - accuracy: 0.3979 - val_loss: 1.0853 - val_accuracy: 0.4230\n",
            "Epoch 197/200\n",
            "67/67 [==============================] - 1s 20ms/step - loss: 1.0819 - accuracy: 0.3979 - val_loss: 1.0855 - val_accuracy: 0.4230\n",
            "Epoch 198/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0808 - accuracy: 0.4045 - val_loss: 1.0854 - val_accuracy: 0.4230\n",
            "Epoch 199/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0828 - accuracy: 0.3909 - val_loss: 1.0854 - val_accuracy: 0.4230\n",
            "Epoch 200/200\n",
            "67/67 [==============================] - 1s 18ms/step - loss: 1.0809 - accuracy: 0.4026 - val_loss: 1.0851 - val_accuracy: 0.4230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x0Cumz7bHhzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "bb3b62b8-b933-4bd4-9105-35257bb2b722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Previsões"
      ],
      "metadata": {
        "id": "EFWMq8xTHkOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy = model.evaluate(x_test, y_test, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZuC2Z_2X84J",
        "outputId": "7459fba8-15b8-454b-a168-060b119ea356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 8ms/step - loss: 1.1047 - accuracy: 0.3508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_probs = model.predict(x_train)\n",
        "val_predict_probs = model.predict(x_val)\n",
        "test_predict_probs = model.predict(x_test)\n",
        "\n",
        "train_predict = np.argmax(train_predict_probs, axis=1)\n",
        "val_predict = np.argmax(val_predict_probs, axis=1)\n",
        "test_predict = np.argmax(test_predict_probs, axis=1)\n",
        "\n",
        "print(train_predict.shape, val_predict.shape, test_predict.shape)\n",
        "print(train_predict)"
      ],
      "metadata": {
        "id": "yfAgKfbvHmUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ecc3952-403d-4c9e-b638-1a5a56a1fc8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 1s 5ms/step\n",
            "10/10 [==============================] - 0s 7ms/step\n",
            "20/20 [==============================] - 0s 5ms/step\n",
            "(2136,) (305,) (610,)\n",
            "[2 2 2 ... 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predict_probs"
      ],
      "metadata": {
        "id": "HozPNVRat1Tk",
        "outputId": "596001d6-3613-4cb8-d190-31d51a7af2fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3387776 , 0.2740084 , 0.387214  ],\n",
              "       [0.3387776 , 0.2740084 , 0.38721403],\n",
              "       [0.33877757, 0.2740083 , 0.38721403],\n",
              "       ...,\n",
              "       [0.33877343, 0.27406427, 0.38716227],\n",
              "       [0.3387734 , 0.27406454, 0.38716206],\n",
              "       [0.33877334, 0.2740659 , 0.38716084]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_matrix = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=test_predict)\n",
        "conf_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAkLOxGv9bgf",
        "outputId": "02a574d2-7b06-482e-8462-c40242fd3526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0, 197],\n",
              "       [  0,   0, 199],\n",
              "       [  0,   0, 214]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotar o Gráfico"
      ],
      "metadata": {
        "id": "BlOdoJmVYwYB"
      }
    }
  ]
}